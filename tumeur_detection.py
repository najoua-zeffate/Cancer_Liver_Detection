# -*- coding: utf-8 -*-
"""Tumeur_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/112nSkNtJiEcAmfiubP1dNhxzl0oNiyQ4
"""

!pip install kaggle

from google.colab import drive
drive.mount('/content/drive',force_remount=True)

! mkdir ~/.kaggle

! cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/kaggle.json

! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download  andrewmvd/liver-tumor-segmentation

! unzip liver-tumor-segmentation

import os
import numpy as np
import matplotlib.pyplot as plt
import nibabel as nib

import glob

import cv2
import imageio
from tqdm.notebook import tqdm
from ipywidgets import *
from PIL import Image

from fastai.basics import *
from fastai.vision.all import *
from fastai.data.transforms import *

#from nibabel.testing import data_path
example_filename = '/content/volume_pt5/volume-50.nii'
#example_filename = '/content/segmentations/segmentation-35.nii'

img = nib.load(example_filename).get_fdata()

img.shape

test = img[:,:,39]
plt.imshow(test)
plt.show()

test = img[:,:,2]
plt.imshow(test)

for i in range(10):
    plt.subplot(10, 10,i + 1)
    plt.imshow(img[:,:, i*10])
    plt.gcf().set_size_inches(10, 10)
plt.show()

for i in range(5):
    plt.subplot(1, 5,i + 1)
    plt.imshow(img[:,:, i])
    plt.gcf().set_size_inches(10, 10)
plt.show()

file_list = []
for path, dirs, filenames in os.walk('/content/segmentations'):
  for filename in filenames:
    file_list.append((path,filename))

for path, dirs, filenames in os.walk('/content/volume_pt1'):
  for filename in filenames:
    file_list.append((path,filename))

for path, dirs, filenames in os.walk('/content/volume_pt2'):
  for filename in filenames:
    file_list.append((path,filename))

for path, dirs, filenames in os.walk('/content/volume_pt3'):
  for filename in filenames:
    file_list.append((path,filename))

for path, dirs, filenames in os.walk('/content/volume_pt4'):
  for filename in filenames:
    file_list.append((path,filename))

for path, dirs, filenames in os.walk('/content/volume_pt5'):
  for filename in filenames:
    file_list.append((path,filename))

import pandas as pd
df_files = pd.DataFrame(file_list, columns =['dirname', 'filename'])
df_files.sort_values(by=['filename'], ascending=True)

"""Lier les images CT avec leur mask"""

df_files["mask_dirname"] = "" ; df_files["mask_filename"] = ""

for i in range(131):
    ct = f"volume-{i}.nii"
    mask = f"segmentation-{i}.nii"
    #ajouter les mask pour chaque image dans le dataframe
    df_files.loc[df_files['filename'] == ct, 'mask_filename'] = mask
    df_files.loc[df_files['filename'] == ct, 'mask_dirname'] = "/content/segmentations"

# supprimer les lignes dont il n'y a pas de mask et trier par filename
df_files = df_files[df_files.mask_filename != ''].sort_values(by=['filename']).reset_index(drop=True) 
print(len(df_files))
df_files

#pour lire un fichier .nii
def read_nii(filepath):
  ct_scan = nib.load(filepath) # load .nii file and return a Nifti1Image object
  array = ct_scan.get_fdata() # transform Nifti1Image object to 3D numpy array
  array = np.rot90(np.array(array)) # rotates array by 90 degrees
  return(array)

sample = 35
sample_ct = read_nii(df_files.loc[sample,'dirname']+"/"+df_files.loc[sample, 'filename'])
sample_mask = read_nii(df_files.loc[sample,'mask_dirname']+"/"+df_files.loc[sample, 'mask_filename'])

print(sample_ct.shape)
print(sample_mask.shape)

print(np.amin(sample_ct), np.amax(sample_ct))
print(np.amin(sample_mask), np.amax(sample_mask))

"""Adjust contrast"""

dicom_windows = types.SimpleNamespace(
    brain=(80,40),
    subdural=(254,100),
    stroke=(8,32),
    brain_bone=(2800,600),
    brain_soft=(375,40),
    lungs=(1500,-600),
    mediastinum=(350,50),
    abdomen_soft=(400,50),
    liver=(150,30),
    spine_soft=(250,50),
    spine_bone=(1800,400),
    custom = (200,60)
)

@patch #  extend the functionality of a tensor class
def windowed(self:Tensor, w, l):
    # adjust the contrast: scales the intensity values of the image to a new range of values between 0 and 1
    px = self.clone()
    px_min = l - w//2
    px_max = l + w//2
    px[px<px_min] = px_min
    px[px>px_max] = px_max
    return (px-px_min) / (px_max-px_min)

plt.imshow(tensor(sample_ct[...,50].astype(np.float32)).windowed(*dicom_windows.liver), cmap=plt.cm.bone);

"""Visualiser CT scan original, windowed CT scan, the mask et la combinaison entre l'image original et le scan  """

def plot_sample(array_list, color_map = 'nipy_spectral'):
    fig = plt.figure(figsize=(18,15))

    plt.subplot(1,4,1)
    plt.imshow(array_list[0], cmap='bone')
    plt.title('Original Image')
    
    plt.subplot(1,4,2)
    plt.imshow(tensor(array_list[0].astype(np.float32)).windowed(*dicom_windows.liver), cmap='bone');
    plt.title('Windowed Image')
    
    plt.subplot(1,4,3)
    plt.imshow(array_list[1], alpha=0.5, cmap=color_map) # 0.5 pour rendre le mask semi transparent
    plt.title('Mask')
    
    plt.subplot(1,4,4)
    plt.imshow(array_list[0], cmap='bone')
    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)
    plt.title('Liver & Mask')

    plt.show()

sample=50
sample_slice = tensor(sample_ct[...,sample].astype(np.float32))

plot_sample([sample_ct[...,sample], sample_mask[...,sample]])

# Conter les valeurs(les pixels) du mask (check the mask quality)
mask = Image.fromarray(sample_mask[...,sample].astype('uint8'), mode="L")
unique, counts = np.unique(mask, return_counts=True)
print( np.array((unique, counts)).T)

class TensorCTScan(TensorImageBW): _show_args = {'cmap':'bone'}

@patch
def freqhist_bins(self:Tensor, n_bins=100):
    "A function to split the range of pixel values into groups, such that each group has around the same number of pixels"
    imsd = self.view(-1).sort()[0]
    t = torch.cat([tensor([0.001]),
                   torch.arange(n_bins).float()/n_bins+(1/2/n_bins),
                   tensor([0.999])])
    t = (len(imsd)*t).long()
    return imsd[t].unique()
    
@patch
def hist_scaled(self:Tensor, brks=None):
    "Scales a tensor using `freqhist_bins` to values between 0 and 1"
    if self.device.type=='cuda': return self.hist_scaled_pt(brks)
    if brks is None: brks = self.freqhist_bins()
    ys = np.linspace(0., 1., len(brks))
    x = self.numpy().flatten()
    x = np.interp(x, brks.numpy(), ys)
    return tensor(x).reshape(self.shape).clamp(0.,1.)
    
    
@patch
def to_nchan(x:Tensor, wins, bins=None):
    # Applies the windows to the tensor and returns a new TensorCTScan object
    res = [x.windowed(*win) for win in wins]
    if not isinstance(bins,int) or bins!=0: res.append(x.hist_scaled(bins).clamp(0,1))
    dim = [0,1][x.dim()==3]
    return TensorCTScan(torch.stack(res, dim=dim))

@patch
def save_jpg(x:(Tensor), path, wins, bins=None, quality=90):
  # Applies the windows, converts the tensor to a JPEG image, and saves it to the specified path
    fn = Path(path).with_suffix('.jpg')
    x = (x.to_nchan(wins, bins)*255).byte()
    im = Image.fromarray(x.permute(1,2,0).numpy(), mode=['RGB','CMYK'][x.shape[0]==4])
    im.save(fn, quality=quality)

_,axs=subplots(1,1)

sample_slice.save_jpg('test.jpg', [dicom_windows.liver,dicom_windows.custom])
show_image(Image.open('test.jpg'), ax=axs[0])

# Generate JPG files for the CT scans and PNG files for the masks
GENERATE_JPG_FILES = True  

if (GENERATE_JPG_FILES) :
    
    path = Path(".")
    # create directories: train_images and train_masks
    os.makedirs('train_images',exist_ok=True)
    os.makedirs('train_masks',exist_ok=True)

    for ii in tqdm(range(0,len(df_files))): # take nii files for training
        curr_ct        = read_nii(df_files.loc[ii,'dirname']+"/"+df_files.loc[ii,'filename'])
        curr_mask      = read_nii(df_files.loc[ii,'mask_dirname']+"/"+df_files.loc[ii,'mask_filename'])
        curr_file_name = str(df_files.loc[ii,'filename']).split('.')[0]
        curr_dim       = curr_ct.shape[2] # 512, 512, curr_dim

        for curr_slice in range(0,curr_dim,3): # export every 10nd slice for training
            data = tensor(curr_ct[...,curr_slice].astype(np.float32))
            mask = Image.fromarray(curr_mask[...,curr_slice].astype('uint8'), mode="L")
            data.save_jpg(f"train_images/{curr_file_name}_slice_{curr_slice}.jpg", [dicom_windows.liver,dicom_windows.custom])
            mask.save(f"train_masks/{curr_file_name}_slice_{curr_slice}_mask.png")
else:
    
    path = Path("../input/liver-segmentation-with-fastai-v2") # read jpg from saved kernel output

print(len(os.listdir('/content/train_images/')))

data = df_files.to_csv('df_files.csv', index = False)

path = Path(".")
bs = 16 # Batch size
im_size = 128 # image size

codes = np.array(["background","liver","tumor"])
    
def get_x(fname:Path): return fname
def label_func(x): return path/'train_masks'/f'{x.stem}_mask.png' # returns the path to the corresponding mask image

tfms = [IntToFloatTensor(),Normalize()] # list of transforms: 1st: converts integers to floats , and 2nd normalizes data

db = DataBlock(blocks=(ImageBlock(),MaskBlock(codes)),  #codes = {"Backround": 0,"Liver": 1,"Tumor": 2}
               batch_tfms=tfms,
               splitter=RandomSplitter(), # randomly splits the data into training and validation sets
               item_tfms=[Resize(im_size)], # resizes images
               get_items=get_image_files, # returns the file names of all images in a directory
               get_y=label_func # the path to the corresponding mask image
              )

ds = db.datasets(source=path/'train_images') # This loads the images and masks into memory, applies the defined transforms and creates the Dataset.

idx=20
imgs = [ds[idx][0],ds[idx][1]]
fig,axs = plt.subplots(1, 2)
for i,ax in enumerate(axs.flatten()):
    ax.axis('off')
    ax.imshow(imgs[i]) #, cmap='gray'

unique, counts = np.unique(array(ds[idx][1]), return_counts=True)

print( np.array((unique, counts)).T)

dls = db.dataloaders(path/'train_images',bs = bs) #, num_workers=0
dls.show_batch()

"""## code"""

df_files.shape

m=len(df_files)
m

import pandas as pd
df_files = pd.read_csv("/content/drive/MyDrive/df_files.csv")

img=[]
tar=[]
path1="/content/drive/MyDrive/train_images/"
path2="/content/drive/MyDrive/train_masks/"
for i in range(0,51):
  m=read_nii(df_files.loc[i,'dirname']+"/"+df_files.loc[i,'filename'])
  p=m.shape[2]
  for j in range(0,p,3):
    img.append(path1+f"volume-{i}_slice_{j}.jpg")
    tar.append(path2+f"volume-{i}_slice_{j}_mask.png")

dataframe2 = pd.DataFrame()
dataframe2['img']=img
dataframe2['tar']=tar
dataframe2.to_csv('dataframe2.csv', index = False)

dataframe2['img'][0:400]

dataframe[4000:]

type(dataframe['img'][0])

image = []
for i in range(0,3):
  image.append(str(img[i]))

dataframe['img'] = dataframe['img'].astype(str)
dataframe['tar'] = dataframe['tar'].astype(str)

import shutil
for i in dataframe2['img'][4000:]:
    # donner la path de l'image
    #image_path = '/chemin/vers/image.jpg'

    # donner le chemin du dossier où l'image est actuellement stockée
    # original_folder = '/content/drive/MyDrive/train_images'

    # donner le chemin du dossier où l'image doit être copiée
    destination_folder = '/content/drive/MyDrive/Folder_image_test'

    # combiner le chemin de l'image et le chemin du dossier original
    full_path = i

    # utiliser shutil.copy pour copier l'image de la source vers la destination
    shutil.copy(full_path, destination_folder)

dataframe['img'][0]

!cp -r '/content/drive/MyDrive/Folder_image_test' '/content/'

from keras.preprocessing.image import ImageDataGenerator

# create an instance of the ImageDataGenerator class
data_train_gen = ImageDataGenerator(rescale=1./255)
data_test_gen = ImageDataGenerator(rescale=1./255)
data_train_mask = ImageDataGenerator(rescale=1./255)
data_test_mask = ImageDataGenerator(rescale=1./255)
#im_size=512
bs = 32
# use the flow_from_dataframe() method to convert the file paths
# to a format that the model can use
train_gen = data_train_gen.flow_from_directory(directory='/content/drive/MyDrive/Folder_image_train/',
                                         target_size=(im_size, im_size),
                                         class_mode='binary',
                                         batch_size=bs)

train_mask = data_test_gen.flow_from_directory(directory='/content/drive/MyDrive/Folder_mask_train/',
                                         target_size=(im_size, im_size),
                                         class_mode='binary',
                                         batch_size=bs)

test_gen = data_train_mask.flow_from_directory(directory='/content/Folder_image_test/',
                                         target_size=(im_size, im_size),
                                         class_mode='binary',
                                         batch_size=bs)

test_mask = data_test_mask.flow_from_directory(directory='/content/drive/MyDrive/Folder_mask_test/',
                                         target_size=(im_size, im_size),
                                         class_mode='binary',
                                         batch_size=bs)

train_img = zip(train_gen, train_mask)
test_img = zip(test_gen, test_mask)

# fit the model using the train_gen generator
model.fit(train_gen, epochs=3, validation_data=test_gen)

dar = os.listdir('/content/drive/MyDrive/Folder_mask_test')

len(dar)

import tensorflow as tf
from tensorflow import keras

input_shape = (im_size, im_size, 1)

# Create the model
model = keras.Sequential()
model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))
model.add(keras.layers.MaxPooling2D((2, 2)))
model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(keras.layers.MaxPooling2D((2, 2)))
model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(keras.layers.UpSampling2D((2, 2)))
model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'))
model.add(keras.layers.UpSampling2D((2, 2)))
model.add(keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy')



from sklearn.model_selection import train_test_split
x = dataframe['img']
y = dataframe['tar']
x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=0)

x_trains = np.array(x_train)
x_vals = np.array(x_val)
y_trains = np.array(y_train)
y_vals = np.array(y_val)

x_trains[0]

from tensorflow.keras.layers import Conv2D,MaxPool2D,Dropout, Activation

from tensorflow.keras import Sequential
model=Sequential([
    Conv2D(16,(3,3),activation='relu',padding='same'),
    Dropout(0.1),
    Conv2D(16,(3,3),activation='relu',padding='same'),
    MaxPool2D((2,2)),
    Conv2D(32,(3,3),activation="relu",padding='same'),
    Dropout(0.1),
    Conv2D(32,(3,3),activation='relu',padding='same'),
    MaxPool2D((2,2)),
    Conv2D(64,(3,3),activation='relu',padding='same'),
    Dropout(0.2),
    Conv2D(64,(3,3),activation='relu',padding='same'),
    MaxPool2D((2,2)),
    Conv2D(128,(3,3),activation='relu',padding='same'),
    Dropout(0.2),
    Conv2D(128,(3,3),activation='relu',padding='same'),
    MaxPool2D(pool_size=(2,2)),
    Conv2D(256,(3,3),activation='relu',padding='same'),
    Dropout(0.3),
    Conv2D(256,(3,3),activation='relu',padding='same'),
    MaxPool2D(pool_size=(2,2)),
    Conv2D(512,(3,3),activation='relu',padding='same'),
    Dropout(0.3),
    Conv2D(512,(3,3),activation='relu',padding='same'),
    MaxPool2D(pool_size=(2,2)),
    u6=Conv2DTranspose(128,(2,2),strides(2,2),padding='same')(c5)
    u6=concatenate([u6,c4])
    c6=conv2D(256,(3,3),activation="relu",padding='same')(u6)
    c6=Dropout(0.2)(c6)
    c6=Conv2D(128,(3,3),activation="relu",padding='same')(c6)

    u6=Conv2DTranspose(128,(2,2),strides(2,2),padding='same')
    u6=concatenate([u6,c4])
    c6=Dropout(0.2)(c6)
    c6=Conv2D(128,(3,3),activation="relu",padding='same')(c6)

    Conv2D(3,(1,1),activation="softmax")

])

from tensorflow.keras import Sequential
model=Sequential([
    Conv2D(16,(3,3),activation='relu',padding='same'),
    Dropout(0.1),
    Conv2D(16,(3,3),activation='relu',padding='same'),
    MaxPool2D((2,2)),
    Conv2D(32,(3,3),activation="relu",padding='same')
    
    #Conv2D(3,(1,1),activation="softmax")

])

from tensorflow.keras.optimizers import Adam

model.compile(optimizer=Adam(),loss='categorical_crossentropy',metrics=['accuracy'])

model.fit(x_trains,y_trains, epochs=10, validation_data=(x_vals,y_vals))

"""# **???**"""

from sklearn.model_selection import train_test_split

# Get all image and mask file names
img_files = get_image_files('/content/train_images')
mask_files = get_image_files('/content/train_masks')

# Split the data into training and test sets
img_train, img_val, mask_train, mask_val = train_test_split(img_files, mask_files, test_size=0.2, random_state=0)



import os
import pandas as pd

# Chemin vers le dossier contenant les images
folder_path = 'train_images'
folder_path_masks = 'train_masks'


# Récupération des noms de fichiers dans le dossier
file_names = os.listdir(folder_path)
file_names_masks = os.listdir(folder_path_masks)

# Création de la dataframe
df = pd.DataFrame({'image_name': file_names[0:2500], 'mask_name': file_names_masks[0:2500]})
# Ajout de la colonne 'path' avec le chemin complet vers chaque fichier
df['path'] = folder_path + '/' + df['image_name']
df['path_mask'] = folder_path_masks + '/' + df['mask_name']

df

# Conter les valeurs(les pixels) du mask (check the mask quality)
mask = Image.fromarray(sample_mask[...,sample].astype('uint8'), mode="L")
unique, counts = np.unique(mask, return_counts=True)
print( np.array((unique, counts)).T)

import os

directory = "train_images"
directory2 = "train_masks"
image_count = len([f for f in os.listdir(directory) if f.endswith(".jpg") or f.endswith(".png")])
image_count2 = len([f for f in os.listdir(directory2) if f.endswith(".jpg") or f.endswith(".png")])
print("Number of images in the directory:", image_count)
print("Number of images in the directory2:", image_count2)

from keras.preprocessing.image import ImageDataGenerator

# create an instance of the ImageDataGenerator class
data_gen = ImageDataGenerator()

# use the flow_from_dataframe() method to convert the file paths
# to a format that the model can use
train_gen = data_gen.flow_from_dataframe(df, x_col=img_train, y_col=mask_train,
                                         target_size=(im_size, im_size),
                                         class_mode='binary',
                                         batch_size=bs)

test_gen = data_gen.flow_from_dataframe(df, x_col=img_val, y_col=mask_val,
                                         target_size=(im_size, im_size),
                                         class_mode='binary',
                                         batch_size=bs)

# fit the model using the train_gen generator
model.fit(train_gen, epochs=10, validation_data=val_gen)

type(img_train)

!rm -r /content/train_images/
!rm -r /content/train_masks/

from torch.utils.data import DataLoader

# Create data loaders for the training and validation sets
#train_loader = DataLoader(img_train, batch_size=bs, shuffle=True)
#val_loader = DataLoader(img_val, batch_size=bs, shuffle=True)

# Train the model using the data loaders
model.fit(x=img_train, y=mask_train, epochs=10, validation_data=(img_val, mask_val))

























sample_mask = read_nii('/content/segmentations/segmentation-20.nii')
mask = Image.fromarray(sample_mask[...,390].astype('uint8'), mode="L")
unique, counts = np.unique(mask, return_counts=True)
print( np.array((unique, counts)).T)

from PIL import Image

def read_png(filepath):
  image = Image.open(filepath)
  array = np.array(image)
  array = np.rot90(np.array(array)) # rotates array by 90 degrees
  return(array)

sample_mask = read_png('/content/train_masks/volume-20_slice_100_mask.png')
mask = Image.fromarray(sample_mask.astype('uint8'), mode="L")
unique, counts = np.unique(mask, return_counts=True)
print( np.array((unique, counts)).T)

learn = unet_learner(dls, resnet34, loss_func=CrossEntropyLossFlat(axis=1), metrics=[foreground_acc, cust_foreground_acc])

# Load saved model   
tfms = [Resize(im_size), IntToFloatTensor(),Normalize()]
learn0               = load_learner('Liver_segmentation',cpu=False )
learn0.dls.transform = tfms

